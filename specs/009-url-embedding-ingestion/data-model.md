# Data Model: Docusaurus → Cohere → Qdrant Ingestion

## Overview
This document defines the data structures and entities used in the ingestion pipeline that transforms Docusaurus content into Qdrant-stored embeddings.

## Core Entities

### Content Chunk
Represents a segment of text extracted from a webpage.

**Fields:**
- `text`: String - The actual content text
- `url`: String - Source URL of the content
- `title`: String - Page title from the source
- `section_heading`: String - Current section heading (if applicable)
- `chunk_index`: Integer - Sequential index of the chunk within the page
- `content_hash`: String - Hash of the content for idempotency
- `word_count`: Integer - Number of words in the chunk
- `char_count`: Integer - Number of characters in the chunk

**Validation Rules:**
- `text` must not be empty
- `url` must be a valid URL format
- `chunk_index` must be >= 0
- `content_hash` must be a valid SHA256 hash

### Embedding Vector
Semantic representation of content chunk text generated by Cohere model.

**Fields:**
- `id`: String - Unique identifier (derived from content hash)
- `vector`: Array<Float> - The embedding vector values
- `payload`: Object - Metadata associated with the vector
  - `url`: String - Source URL
  - `page_title`: String - Original page title
  - `section_heading`: String - Section heading
  - `chunk_index`: Integer - Position in the original page
  - `text`: String - Original text content
  - `content_hash`: String - Hash of the original content

**Validation Rules:**
- `vector` must match Cohere embedding dimension (typically 1024 for multilingual v3)
- `id` must be unique within the collection
- `payload` must contain all required metadata fields

### Ingestion Job
Represents a single execution of the ingestion pipeline.

**Fields:**
- `job_id`: String - Unique identifier for the job
- `start_time`: DateTime - When the job started
- `end_time`: DateTime - When the job completed
- `status`: Enum - Current status (pending, running, completed, failed)
- `total_urls_discovered`: Integer - Number of URLs found
- `urls_processed`: Integer - Number of URLs successfully processed
- `chunks_created`: Integer - Number of content chunks created
- `vectors_stored`: Integer - Number of vectors successfully stored in Qdrant
- `errors`: Array<Object> - List of errors encountered during the job
- `processing_stats`: Object - Statistics about the processing
  - `avg_chunk_size`: Float - Average size of chunks created
  - `processing_rate`: Float - Pages processed per minute

**Validation Rules:**
- `job_id` must be unique
- `start_time` must be before `end_time` (when job is completed)
- `urls_processed` must be <= `total_urls_discovered`
- `vectors_stored` must be <= `chunks_created`

### Configuration
Runtime configuration for the ingestion pipeline.

**Fields:**
- `cohere_model`: String - Cohere embedding model to use
- `chunk_size`: Integer - Maximum size of text chunks (characters)
- `chunk_overlap`: Integer - Overlap between adjacent chunks (characters)
- `qdrant_collection_name`: String - Name of the Qdrant collection
- `vector_dimension`: Integer - Dimension of the embedding vectors
- `request_timeout`: Integer - Timeout for HTTP requests (seconds)
- `retry_attempts`: Integer - Number of retry attempts for failed requests
- `concurrent_workers`: Integer - Number of concurrent workers for processing

**Validation Rules:**
- `chunk_size` must be > 0
- `chunk_overlap` must be >= 0 and < `chunk_size`
- `vector_dimension` must match the Cohere model output
- `request_timeout` must be > 0
- `retry_attempts` must be >= 0
- `concurrent_workers` must be > 0

## Relationships

### Content Chunk → Embedding Vector
One-to-one relationship: Each content chunk generates exactly one embedding vector.

### Ingestion Job → Content Chunk
One-to-many relationship: Each ingestion job processes multiple content chunks.

### Ingestion Job → Embedding Vector
One-to-many relationship: Each ingestion job results in multiple embedding vectors being stored.

## State Transitions

### Ingestion Job States
- `pending` → `running`: When the job starts processing URLs
- `running` → `completed`: When all URLs are processed successfully
- `running` → `failed`: When a critical error occurs during processing
- `completed` → `running`: When the job is re-executed (idempotent operation)

## Data Flow

1. **URL Discovery**: Discover URLs from sitemap or crawling → Store in Ingestion Job
2. **Content Extraction**: Extract Content Chunks from each URL → Track in Ingestion Job
3. **Embedding Generation**: Convert Content Chunks to Embedding Vectors → Track in Ingestion Job
4. **Vector Storage**: Store Embedding Vectors in Qdrant → Update Ingestion Job stats